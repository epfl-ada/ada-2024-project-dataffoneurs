{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths constants\n",
    "PLOT_DATA_PATH = \"../data/plot_summaries.txt\"\n",
    "MOVIE_DATA_PATH = \"../data/movie.metadata.tsv\"\n",
    "CLUSTER_NAME_DATA_PATH = \"../data/name.clusters.txt\"\n",
    "CHARACTER_DATA_PATH = \"../data/character.metadata.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the data into two main categories, movie related data and actors related data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning movie metada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to parse dictionary-like strings in the file and separate keys and values\n",
    "\"\"\"\n",
    "def parse_dict_column(column):\n",
    "    parsed_keys = []\n",
    "    parsed_values = []\n",
    "    \n",
    "    for item in column:\n",
    "        # Convert string representation of dictionary to actual dictionary\n",
    "        item_dict = ast.literal_eval(item)\n",
    "        parsed_keys.append(\", \".join(item_dict.keys()))\n",
    "        parsed_values.append(\", \".join(item_dict.values()))\n",
    "    \n",
    "    return parsed_keys, parsed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48404</th>\n",
       "      <td>16655899</td>\n",
       "      <td>/m/03yk0yn</td>\n",
       "      <td>Sex Hygiene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Short Film, Black-and-white, Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22858</th>\n",
       "      <td>4305023</td>\n",
       "      <td>/m/0bw3_j</td>\n",
       "      <td>Global Heresy</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia_movie_ID Freebase_movie_ID     Movie_name  \\\n",
       "48404            16655899        /m/03yk0yn    Sex Hygiene   \n",
       "22858             4305023         /m/0bw3_j  Global Heresy   \n",
       "\n",
       "       Movie_release_date  Movie_box_office_revenue  Movie_runtime  \\\n",
       "48404                 NaN                       NaN           30.0   \n",
       "22858              2002.0                       NaN          106.0   \n",
       "\n",
       "        Movie_languages           Movie_countries  \\\n",
       "48404  English Language  United States of America   \n",
       "22858  English Language  United States of America   \n",
       "\n",
       "                                   Movie_genres  \n",
       "48404  Short Film, Black-and-white, Documentary  \n",
       "22858                                    Comedy  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Function to load and clean movie metadata, returns a dataframe with cleaned movie data\n",
    "\"\"\"\n",
    "def load_and_clean_movie_data():\n",
    "    # Load the movie metadata\n",
    "    df_movie_metadata = pd.read_csv(\n",
    "        MOVIE_DATA_PATH, sep='\\t', header=None, \n",
    "        names=[\n",
    "            'Wikipedia_movie_ID', 'Freebase_movie_ID', 'Movie_name', \n",
    "            'Movie_release_date', 'Movie_box_office_revenue', 'Movie_runtime',\n",
    "            'Movie_languages_(Freebase ID:name tuples)', 'Movie_countries_(Freebase ID:name tuples)',\n",
    "            'Movie_genres_(Freebase ID:name tuples)'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Parse 'languages', 'countries', and 'genres' columns\n",
    "    df_movie_metadata['id_movie_languages'], df_movie_metadata['Movie_languages'] = parse_dict_column(df_movie_metadata['Movie_languages_(Freebase ID:name tuples)'])\n",
    "    df_movie_metadata['id_Movie_countries'], df_movie_metadata['Movie_countries'] = parse_dict_column(df_movie_metadata['Movie_countries_(Freebase ID:name tuples)'])\n",
    "    df_movie_metadata['id_Movie_genres'], df_movie_metadata['Movie_genres'] = parse_dict_column(df_movie_metadata['Movie_genres_(Freebase ID:name tuples)'])\n",
    "\n",
    "    # Convert dates to datetime and extract the year\n",
    "    df_movie_metadata['Movie_release_date'] = pd.to_datetime(df_movie_metadata['Movie_release_date'], errors='coerce').dt.year\n",
    "\n",
    "    # Select and rename the columns as required\n",
    "    cleaned_df_movie_metadata = df_movie_metadata[[\n",
    "        'Wikipedia_movie_ID', 'Freebase_movie_ID', 'Movie_name', 'Movie_release_date', \n",
    "        'Movie_box_office_revenue', 'Movie_runtime', 'id_movie_languages', \n",
    "        'Movie_languages', 'id_Movie_countries', 'Movie_countries', \n",
    "        'id_Movie_genres', 'Movie_genres'\n",
    "    ]]\n",
    "\n",
    "    # Drop unwanted id columns\n",
    "    columns_to_drop = ['id_movie_languages', 'id_Movie_genres', 'id_Movie_countries']\n",
    "    cleaned_df_movie_metadata = cleaned_df_movie_metadata.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Convert floats of box office and years to nullable integers, keeping NaNs as np.nan\n",
    "    cleaned_df_movie_metadata['Movie_box_office_revenue'] = pd.to_numeric(cleaned_df_movie_metadata['Movie_box_office_revenue'], errors='coerce')\n",
    "    cleaned_df_movie_metadata['Movie_release_date'] = pd.to_numeric(cleaned_df_movie_metadata['Movie_release_date'], errors='coerce')\n",
    "\n",
    "    #need to drop a line that has some weird encodings \n",
    "    cleaned_df_movie_metadata = cleaned_df_movie_metadata.map(lambda x: x.encode('utf-8', 'ignore').decode('utf-8') if isinstance(x, str) else x)\n",
    "\n",
    "    # Replace any <NA> with np.nan for uniform NaNs\n",
    "    cleaned_df_movie_metadata = cleaned_df_movie_metadata.replace({pd.NA: np.nan})\n",
    "\n",
    "    return cleaned_df_movie_metadata\n",
    "\n",
    "df_movie_metadata = load_and_clean_movie_data()\n",
    "df_movie_metadata.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81741, 9)\n",
      "81741\n"
     ]
    }
   ],
   "source": [
    "print(df_movie_metadata.shape)\n",
    "print(df_movie_metadata[\"Wikipedia_movie_ID\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\"\"\"\n",
    "Helper function to clean plot texts from unwanted annotations and tags\n",
    "\"\"\"\n",
    "def clean_plot(txt):\n",
    "\n",
    "    #Remove URLs\n",
    "    txt = re.sub(r\"http\\S+|www\\.\\S+\", '', txt)\n",
    "\n",
    "    #Remove HTML tags\n",
    "    txt = re.sub(r'<.*?>', '', txt)\n",
    "\n",
    "    #Remove {{annotations}}\n",
    "    txt = re.sub(r'\\{\\{.*?\\}\\}', '', txt)\n",
    "\n",
    "    #Remove the ([[ annotation that is never closed\n",
    "    txt = re.sub(r'\\(\\[\\[', '', txt)\n",
    "\n",
    "    #Remove the synopsis from context\n",
    "    txt = re.sub(r'Synopsis from', '', txt)\n",
    "\n",
    "    #Remove <ref...}} tags\n",
    "    txt = re.sub(r'<ref[^}]*}}', '', txt)\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_plots_data():\n",
    "    df_plot_summaries = pd.read_csv(PLOT_DATA_PATH, sep='\\t', header=None,  names=['Wikipedia_movie_ID', 'summary'])\n",
    "    df_plot_summaries['summary'] = df_plot_summaries['summary'].apply(clean_plot)\n",
    "    return df_plot_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging metadata and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81840, 10)\n"
     ]
    }
   ],
   "source": [
    "df_movie_plots = load_and_clean_plots_data()\n",
    "df_movie_data = df_movie_plots.merge(df_movie_metadata, on='Wikipedia_movie_ID', how='outer')\n",
    "print(df_movie_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting clean data in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_data.to_csv('../../data/our_movie_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to load cluster data, returns a dataframe with cleaned cluster data\n",
    "\"\"\"\n",
    "def load_and_clean_cluster_data():\n",
    "    #get cluster data\n",
    "    file_path = \"../data/tvtropes.clusters.txt\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Replace `{\"char\": ` with a simpler delimiter like a tab\n",
    "    lines = [line.replace('{\"char\": ', '').replace(', \"movie\": ', '\\t')\n",
    "            .replace(', \"id\": ', '\\t').replace('}', '')\n",
    "            .replace(', \"actor\": ', '\\t').replace('\\t\\t', '\\t') for line in lines]\n",
    "\n",
    "    with open(\"../data/pro_tvtropes.clusters.txt\", \"w\") as file:\n",
    "        file.writelines(lines)\n",
    "    file_path = \"../data/pro_tvtropes.clusters.txt\"\n",
    "\n",
    "    # Load the processed file\n",
    "    df_clusters_tvtropes = pd.read_csv(file_path, sep='\\t', header=None, names=['character_types', 'character', 'movie','Freebase_character/actor_map_ID','Actor name'])\n",
    "\n",
    "    # Replace any <NA> with np.nan for uniform NaNs\n",
    "    df_clusters_tvtropes = df_clusters_tvtropes.replace({pd.NA: np.nan})\n",
    "    return df_clusters_tvtropes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(501, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_types</th>\n",
       "      <th>character</th>\n",
       "      <th>movie</th>\n",
       "      <th>Freebase_character/actor_map_ID</th>\n",
       "      <th>Actor name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>granola_person</td>\n",
       "      <td>Max Dennison</td>\n",
       "      <td>Hocus Pocus</td>\n",
       "      <td>/m/02vd92w</td>\n",
       "      <td>Omri Katz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absent_minded_professor</td>\n",
       "      <td>Professor Keenbean</td>\n",
       "      <td>Richie Rich</td>\n",
       "      <td>/m/02vchl3</td>\n",
       "      <td>Michael McShane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>romantic_runnerup</td>\n",
       "      <td>Proteus</td>\n",
       "      <td>Sinbad: Legend of the Seven Seas</td>\n",
       "      <td>/m/02vc177</td>\n",
       "      <td>Joseph Fiennes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             character_types           character  \\\n",
       "278           granola_person        Max Dennison   \n",
       "1    absent_minded_professor  Professor Keenbean   \n",
       "417        romantic_runnerup             Proteus   \n",
       "\n",
       "                                movie Freebase_character/actor_map_ID  \\\n",
       "278                       Hocus Pocus                      /m/02vd92w   \n",
       "1                         Richie Rich                      /m/02vchl3   \n",
       "417  Sinbad: Legend of the Seven Seas                      /m/02vc177   \n",
       "\n",
       "          Actor name  \n",
       "278        Omri Katz  \n",
       "1    Michael McShane  \n",
       "417   Joseph Fiennes  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clusters_tvtropes = load_and_clean_cluster_data()\n",
    "print(df_clusters_tvtropes.shape)\n",
    "df_clusters_tvtropes.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_character_data():\n",
    "    \n",
    "    # load from csv\n",
    "    df_clusters_name = pd.read_csv(CLUSTER_NAME_DATA_PATH, sep='\\t', header=None, names=['unique_character_name', 'Freebase_character/actor_map_ID'])\n",
    "    df_character_metadata = pd.read_csv(CHARACTER_DATA_PATH, sep='\\t', header=None, \n",
    "                                    names=[\n",
    "                                        'Wikipedia movie ID','Freebase_movie_ID', 'Movie_release_date',\n",
    "                                        'Character_name', 'Actor_date_of_birth', 'Actor_gender',\n",
    "                                        'Actor_height_(in meters)', 'Actor_ethnicity_(Freebase ID)',\n",
    "                                        'Actor name', 'Actor_age_at_movie_release', 'Freebase_character/actor_map_ID',\n",
    "                                        'Freebase_character_ID', 'Freebase_actor_ID'\n",
    "                                        ])\n",
    "    #drop unwanted columns\n",
    "    columns_to_drop = ['Actor_height_(in meters)',  'Movie_release_date']\n",
    "    df_character_metadata = df_character_metadata.drop(columns=columns_to_drop)\n",
    "\n",
    "    #keep only year of birth\n",
    "    df_character_metadata['Actor_date_of_birth'] = pd.to_datetime(df_character_metadata['Actor_date_of_birth'], errors='coerce').dt.year\n",
    "\n",
    "    #merge character info with their unique names\n",
    "    df_character_metadata = df_character_metadata.merge(df_clusters_name, on='Freebase_character/actor_map_ID', how='outer')\n",
    "\n",
    "    #Check actor age is bigger equal 0 and smaller than 110, else replace with NaN\n",
    "    df_character_metadata['Actor_age_at_movie_release'] = df_character_metadata['Actor_age_at_movie_release'].apply(lambda x: x if 0 <= x <= 110 else np.nan)\n",
    "\n",
    "    # Replace any <NA> with np.nan for uniform NaNs\n",
    "    df_character_metadata = df_character_metadata.replace({pd.NA: np.nan})\n",
    "        \n",
    "    return df_character_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450674, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Character_name</th>\n",
       "      <th>Actor_date_of_birth</th>\n",
       "      <th>Actor_gender</th>\n",
       "      <th>Actor_ethnicity_(Freebase ID)</th>\n",
       "      <th>Actor name</th>\n",
       "      <th>Actor_age_at_movie_release</th>\n",
       "      <th>Freebase_character/actor_map_ID</th>\n",
       "      <th>Freebase_character_ID</th>\n",
       "      <th>Freebase_actor_ID</th>\n",
       "      <th>unique_character_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315880</th>\n",
       "      <td>31910060</td>\n",
       "      <td>/m/0h146vw</td>\n",
       "      <td>Micky</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>M</td>\n",
       "      <td>/m/041rx</td>\n",
       "      <td>James Caan</td>\n",
       "      <td>70.0</td>\n",
       "      <td>/m/0h146vk</td>\n",
       "      <td>/m/0h146vm</td>\n",
       "      <td>/m/0252fh</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74502</th>\n",
       "      <td>32014995</td>\n",
       "      <td>/m/0gx0h2g</td>\n",
       "      <td>Randy Dobson</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>M</td>\n",
       "      <td>/m/07hwkr</td>\n",
       "      <td>Eric Christian Olsen</td>\n",
       "      <td>24.0</td>\n",
       "      <td>/m/04j2k6q</td>\n",
       "      <td>/m/0h5jt_g</td>\n",
       "      <td>/m/0959pn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165942</th>\n",
       "      <td>3843878</td>\n",
       "      <td>/m/02vkdjr</td>\n",
       "      <td>Bob</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Larry Pine</td>\n",
       "      <td>61.0</td>\n",
       "      <td>/m/0cg4s79</td>\n",
       "      <td>/m/0h5wxmq</td>\n",
       "      <td>/m/099pjr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Wikipedia movie ID Freebase_movie_ID Character_name  \\\n",
       "315880            31910060        /m/0h146vw          Micky   \n",
       "74502             32014995        /m/0gx0h2g   Randy Dobson   \n",
       "165942             3843878        /m/02vkdjr            Bob   \n",
       "\n",
       "        Actor_date_of_birth Actor_gender Actor_ethnicity_(Freebase ID)  \\\n",
       "315880               1940.0            M                      /m/041rx   \n",
       "74502                1977.0            M                     /m/07hwkr   \n",
       "165942               1945.0            M                           NaN   \n",
       "\n",
       "                  Actor name  Actor_age_at_movie_release  \\\n",
       "315880            James Caan                        70.0   \n",
       "74502   Eric Christian Olsen                        24.0   \n",
       "165942            Larry Pine                        61.0   \n",
       "\n",
       "       Freebase_character/actor_map_ID Freebase_character_ID  \\\n",
       "315880                      /m/0h146vk            /m/0h146vm   \n",
       "74502                       /m/04j2k6q            /m/0h5jt_g   \n",
       "165942                      /m/0cg4s79            /m/0h5wxmq   \n",
       "\n",
       "       Freebase_actor_ID unique_character_name  \n",
       "315880         /m/0252fh                   NaN  \n",
       "74502          /m/0959pn                   NaN  \n",
       "165942         /m/099pjr                   NaN  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_character_metadata = load_and_clean_character_data()\n",
    "print(df_character_metadata.shape)\n",
    "df_character_metadata.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding to the metadata on their ids character types and checking that all unique character names are instanciated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450742, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Character_name</th>\n",
       "      <th>Actor_date_of_birth</th>\n",
       "      <th>Actor_gender</th>\n",
       "      <th>Actor_ethnicity_(Freebase ID)</th>\n",
       "      <th>Actor name</th>\n",
       "      <th>Actor_age_at_movie_release</th>\n",
       "      <th>Freebase_character/actor_map_ID</th>\n",
       "      <th>Freebase_character_ID</th>\n",
       "      <th>Freebase_actor_ID</th>\n",
       "      <th>unique_character_name</th>\n",
       "      <th>character_types</th>\n",
       "      <th>character</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317102</th>\n",
       "      <td>29758182.0</td>\n",
       "      <td>/m/0fq1f0q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>M</td>\n",
       "      <td>/m/01xhh5</td>\n",
       "      <td>Park Yong-Ha</td>\n",
       "      <td>31.0</td>\n",
       "      <td>/m/0h1l1fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/03j2spj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180981</th>\n",
       "      <td>14023727.0</td>\n",
       "      <td>/m/03cr8_w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Icíar Bollaín</td>\n",
       "      <td>18.0</td>\n",
       "      <td>/m/0chcxc2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/026np8p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282148</th>\n",
       "      <td>12113466.0</td>\n",
       "      <td>/m/02vq6zf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan Merlin</td>\n",
       "      <td>30.0</td>\n",
       "      <td>/m/0ggbxmf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0c3_jl3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113806</th>\n",
       "      <td>4102452.0</td>\n",
       "      <td>/m/0bj2cm</td>\n",
       "      <td>Chandramukhi</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>F</td>\n",
       "      <td>/m/0bpjh3</td>\n",
       "      <td>Indrani Haldar</td>\n",
       "      <td>31.0</td>\n",
       "      <td>/m/09hz8c9</td>\n",
       "      <td>/m/0h5sy65</td>\n",
       "      <td>/m/02q38w4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30272</th>\n",
       "      <td>11350840.0</td>\n",
       "      <td>/m/02r8l03</td>\n",
       "      <td>Doctor Watson</td>\n",
       "      <td>1895.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nigel Bruce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/02vd8sc</td>\n",
       "      <td>/m/0cgryr0</td>\n",
       "      <td>/m/02l99f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273550</th>\n",
       "      <td>26554241.0</td>\n",
       "      <td>/m/0bh8pk4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cameron Mitchell</td>\n",
       "      <td>55.0</td>\n",
       "      <td>/m/0gdgqtm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/07tvwy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Wikipedia movie ID Freebase_movie_ID Character_name  \\\n",
       "317102          29758182.0        /m/0fq1f0q            NaN   \n",
       "180981          14023727.0        /m/03cr8_w            NaN   \n",
       "282148          12113466.0        /m/02vq6zf            NaN   \n",
       "113806           4102452.0         /m/0bj2cm   Chandramukhi   \n",
       "30272           11350840.0        /m/02r8l03  Doctor Watson   \n",
       "273550          26554241.0        /m/0bh8pk4            NaN   \n",
       "\n",
       "        Actor_date_of_birth Actor_gender Actor_ethnicity_(Freebase ID)  \\\n",
       "317102               1977.0            M                     /m/01xhh5   \n",
       "180981               1967.0            F                           NaN   \n",
       "282148               1925.0            M                           NaN   \n",
       "113806               1971.0            F                     /m/0bpjh3   \n",
       "30272                1895.0            M                           NaN   \n",
       "273550               1918.0            M                           NaN   \n",
       "\n",
       "              Actor name  Actor_age_at_movie_release  \\\n",
       "317102      Park Yong-Ha                        31.0   \n",
       "180981     Icíar Bollaín                        18.0   \n",
       "282148        Jan Merlin                        30.0   \n",
       "113806    Indrani Haldar                        31.0   \n",
       "30272        Nigel Bruce                         NaN   \n",
       "273550  Cameron Mitchell                        55.0   \n",
       "\n",
       "       Freebase_character/actor_map_ID Freebase_character_ID  \\\n",
       "317102                      /m/0h1l1fb                   NaN   \n",
       "180981                      /m/0chcxc2                   NaN   \n",
       "282148                      /m/0ggbxmf                   NaN   \n",
       "113806                      /m/09hz8c9            /m/0h5sy65   \n",
       "30272                       /m/02vd8sc            /m/0cgryr0   \n",
       "273550                      /m/0gdgqtm                   NaN   \n",
       "\n",
       "       Freebase_actor_ID unique_character_name character_types character movie  \n",
       "317102        /m/03j2spj                   NaN             NaN       NaN   NaN  \n",
       "180981        /m/026np8p                   NaN             NaN       NaN   NaN  \n",
       "282148        /m/0c3_jl3                   NaN             NaN       NaN   NaN  \n",
       "113806        /m/02q38w4                   NaN             NaN       NaN   NaN  \n",
       "30272          /m/02l99f                   NaN             NaN       NaN   NaN  \n",
       "273550         /m/07tvwy                   NaN             NaN       NaN   NaN  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_character_data = df_character_metadata.merge(df_clusters_tvtropes, on=['Freebase_character/actor_map_ID', 'Actor name'], how='outer')\n",
    "df_clusters_name = pd.read_csv(CLUSTER_NAME_DATA_PATH, sep='\\t', header=None, names=['unique_character_name', 'Freebase_character/actor_map_ID'])\n",
    "df_character_data = df_character_data.merge(df_clusters_name, on=['Freebase_character/actor_map_ID', \"unique_character_name\"], how='outer')\n",
    "print(df_character_data.shape)\n",
    "df_character_data.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract a csv for actor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_character_data.to_csv('../../data/our_character_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
