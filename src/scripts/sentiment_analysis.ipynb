{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathieu\\anaconda3\\envs\\ada\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import pipeline\n",
    "from scipy.special import softmax\n",
    "\n",
    "import ast\n",
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Colonne_1  Colonne_2  Colonne_3  Colonne_4  Colonne_5  Colonne_6  \\\n",
      "Ligne_1          26         27         99         57         73       83.0   \n",
      "Ligne_2          78         41         81          4         24       10.0   \n",
      "Ligne_3          49         45         46         35         70        7.0   \n",
      "Ligne_4          69         78         24         64         63       40.0   \n",
      "Ligne_5          55         54         26         29         95       53.0   \n",
      "Ligne_6          11         88         56          5         51        NaN   \n",
      "Ligne_7          33         77         74         18         22       44.0   \n",
      "Ligne_8          70         68         54         87         97       63.0   \n",
      "Ligne_9          67         11         44         58         58       53.0   \n",
      "Ligne_10         52         66         14         42         43       92.0   \n",
      "\n",
      "          Colonne_7  Colonne_8  Colonne_9  Colonne_10  \n",
      "Ligne_1          75         58         16          77  \n",
      "Ligne_2          83         74         45          77  \n",
      "Ligne_3          44          7         73          74  \n",
      "Ligne_4          96         93         49          36  \n",
      "Ligne_5          59          8         88           7  \n",
      "Ligne_6          90          1         49          57  \n",
      "Ligne_7          13         74         45          25  \n",
      "Ligne_8           9         50         57          90  \n",
      "Ligne_9          49         53         54          25  \n",
      "Ligne_10         82         66         65          58  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colonne_1</th>\n",
       "      <th>Colonne_2</th>\n",
       "      <th>Colonne_3</th>\n",
       "      <th>Colonne_4</th>\n",
       "      <th>Colonne_5</th>\n",
       "      <th>Colonne_6</th>\n",
       "      <th>Colonne_7</th>\n",
       "      <th>Colonne_8</th>\n",
       "      <th>Colonne_9</th>\n",
       "      <th>Colonne_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ligne_1</th>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>99</td>\n",
       "      <td>57</td>\n",
       "      <td>73</td>\n",
       "      <td>6889.0</td>\n",
       "      <td>75</td>\n",
       "      <td>58</td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ligne_2</th>\n",
       "      <td>78</td>\n",
       "      <td>41</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83</td>\n",
       "      <td>74</td>\n",
       "      <td>45</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ligne_3</th>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ligne_4</th>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ligne_5</th>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>95</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>59</td>\n",
       "      <td>8</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ligne_6</th>\n",
       "      <td>11</td>\n",
       "      <td>88</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ligne_7</th>\n",
       "      <td>33</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>13</td>\n",
       "      <td>74</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ligne_8</th>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "      <td>54</td>\n",
       "      <td>87</td>\n",
       "      <td>97</td>\n",
       "      <td>3969.0</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ligne_9</th>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>49</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ligne_10</th>\n",
       "      <td>52</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>8464.0</td>\n",
       "      <td>82</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Colonne_1  Colonne_2  Colonne_3  Colonne_4  Colonne_5  Colonne_6  \\\n",
       "Ligne_1          26         27         99         57         73     6889.0   \n",
       "Ligne_2          78         41         81          4         24      100.0   \n",
       "Ligne_3          49         45         46         35         70       49.0   \n",
       "Ligne_4          69         78         24         64         63     1600.0   \n",
       "Ligne_5          55         54         26         29         95     2809.0   \n",
       "Ligne_6          11         88         56          5         51        NaN   \n",
       "Ligne_7          33         77         74         18         22     1936.0   \n",
       "Ligne_8          70         68         54         87         97     3969.0   \n",
       "Ligne_9          67         11         44         58         58     2809.0   \n",
       "Ligne_10         52         66         14         42         43     8464.0   \n",
       "\n",
       "          Colonne_7  Colonne_8  Colonne_9  Colonne_10  \n",
       "Ligne_1          75         58         16          77  \n",
       "Ligne_2          83         74         45          77  \n",
       "Ligne_3          44          7         73          74  \n",
       "Ligne_4          96         93         49          36  \n",
       "Ligne_5          59          8         88           7  \n",
       "Ligne_6          90          1         49          57  \n",
       "Ligne_7          13         74         45          25  \n",
       "Ligne_8           9         50         57          90  \n",
       "Ligne_9          49         53         54          25  \n",
       "Ligne_10         82         66         65          58  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 100, size=(10, 10)),\n",
    "                               columns=[f'Colonne_{i+1}' for i in range(10)],\n",
    "                               index=[f'Ligne_{i+1}' for i in range(10)])\n",
    "df.iloc[5, 5] = np.nan\n",
    "print(df)\n",
    "df['Colonne_6'] = df['Colonne_6'].dropna().apply(lambda x : x**2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/our_movie_data_extended.csv\"\n",
    "df_extended = pd.read_csv(DATA_PATH, index_col=\"Wikipedia_movie_ID\")\n",
    "df_extended['category'] = df_extended['category'].dropna().apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After being pulled through a time portal, Ash Williams lands in 1300 AD, where he is almost immediately captured by Lord Arthur\\'s men, who suspect him to be an agent for Duke Henry, with whom Arthur is at war. He is enslaved along with the captured Henry, his gun and chainsaw confiscated, and is taken to a castle. Ash is thrown in a pit where he fights off a Deadite and regains his weapons from Arthur\\'s Wise Man. After demanding Henry and his men be set free  and killing a deadite in full view of everyone, Ash is celebrated as a hero. He also grows attracted to Sheila, the sister of one of Arthur\\'s fallen knights. According to the Wise Man, the only way Ash can return to his time is to retrieve the Necronomicon Ex-Mortis. After bidding goodbye to Sheila, Ash starts his search for the Necronomicon. As he enters a haunted forest, an unseen force pursues Ash through the woods. Fleeing, he ducks into a windmill where he crashes into a mirror. The small reflections of Ash climb out from the shattered mirror and torment him. One of the reflections dives down Ash\\'s throat and uses his body to become a life-sized clone of Ash and attack him, after which Ash kills and buries the clone. When he arrives at the Necronomicon\\'s location, he finds three books instead of one. Ash eventually finds the real one and attempts to say the magic phrase that will allow him to remove the book safely — \"Klaatu verata nicto\". However, forgetting the last word, he tries to trick the book by mumbling/coughing the missing word. He then grabs the book from the cradle, and rushes back to the castle, while the dead rise from graves all around. During Ash\\'s panicked ride back, his evil copy rises from his grave and unites the Deadites into the Army of Darkness. Despite causing the predicament faced by the Medieval soldiers, Ash initially demands to be returned to his own time. However, Sheila is captured by a Flying Deadite, and later transformed into a Deadite. Ash becomes determined to lead the humans against the army of the dead. Reluctantly, the people agree to join Ash. Using scientific knowledge from textbooks in the trunk of his 1973 Oldsmobile Delta 88, and enlisting the help of Duke Henry, Ash successfully leads the medieval soldiers to victory over the Deadites and Evil Ash, saving Sheila and bringing peace between Arthur and Henry in the process. After this, he is brought back to his own time using a potion made from the Necronomicon. Later, Ash is at the S-Mart store telling a male co-worker  all about his adventure back in time, and how he could have been king. A female customer becomes possessed by a demon and starts wreaking havoc on the store, and Ash slays the creature.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extended['summary'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_to_segment(summary):    \n",
    "    if pd.isna(summary):\n",
    "        return []\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    sentences = summary.split(\". \")\n",
    "    sentences = [s.strip() for s in sentences if s]  # Supprimer les espaces et les phrases vides\n",
    "\n",
    "    embeddings = model.encode(sentences)\n",
    "\n",
    "    similarities = [util.pytorch_cos_sim(embeddings[i], embeddings[i+1]).item() for i in range(len(embeddings)-1)]\n",
    "\n",
    "    # 4. Identifier les points de transition basés sur un seuil de similarité\n",
    "    threshold = 0.5 \n",
    "    segments = []\n",
    "    current_segment = [sentences[0]]\n",
    "\n",
    "    for i, similarity in enumerate(similarities):\n",
    "        if similarity < threshold:  \n",
    "            segments.append(\" \".join(current_segment))  \n",
    "            current_segment = []  \n",
    "        current_segment.append(sentences[i + 1])\n",
    "\n",
    "    segments.append(\" \".join(current_segment))\n",
    "    #if we have only empty list, return an empty list\n",
    "    if all(len(sublist) == 0 for sublist in segments):\n",
    "        return []\n",
    "    return segments\n",
    "\n",
    "def segments_to_emotions(segments):\n",
    "    \"\"\"\n",
    "    take a segments (list of segment) and compute the probability of each emotions for each segment\n",
    "    \"\"\"\n",
    "    #the emotions are anger, fear, joy, love, sadness, surprise and neutral\n",
    "    \n",
    "    #if segments is empty, return an \"empty dataframe\" with nan\n",
    "    if len(segments) == 0:\n",
    "        return pd.DataFrame([[np.nan] * 7], columns=['neutral', 'joy', 'surprise', 'disgust', 'fear', 'anger', 'sadness'])\n",
    "    \n",
    "    classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", top_k=None)\n",
    "    emotions = classifier(segments)\n",
    "    emotions_flattened = [{item['label']: item['score'] for item in entry} for entry in emotions]\n",
    "    df_emotions =  pd.DataFrame(emotions_flattened)\n",
    "    return df_emotions\n",
    "\n",
    "def create_df_emotions_with_every_film(df):\n",
    "    df_emotions = pd.DataFrame()\n",
    "    for idx, segments in tqdm(enumerate(df['summary_segmented'].dropna())): #on pourra retirer le dropna quand on calculera cela pour tout les summaries\n",
    "        emotions = segments_to_emotions(segments)\n",
    "        #set the index to be the UID of the film\n",
    "        emotions.index = [df.index[idx]] * len(emotions)\n",
    "        emotions['category'] = df['category']\n",
    "        df_emotions = pd.concat([df_emotions, emotions])\n",
    "    return df_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [52:58,  3.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>joy</th>\n",
       "      <th>surprise</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>sadness</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.446200</td>\n",
       "      <td>0.147301</td>\n",
       "      <td>0.138631</td>\n",
       "      <td>0.118294</td>\n",
       "      <td>0.077507</td>\n",
       "      <td>0.038214</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>0.065840</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.096655</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.782216</td>\n",
       "      <td>0.042827</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>[Others, Family/Animation, Horror, Drama, Fant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>0.144797</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.014325</td>\n",
       "      <td>0.214261</td>\n",
       "      <td>0.085287</td>\n",
       "      <td>0.397198</td>\n",
       "      <td>0.141074</td>\n",
       "      <td>[Others, Family/Animation, Horror, Drama, Fant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>0.042516</td>\n",
       "      <td>0.018551</td>\n",
       "      <td>0.013053</td>\n",
       "      <td>0.073122</td>\n",
       "      <td>0.021625</td>\n",
       "      <td>0.737254</td>\n",
       "      <td>0.093879</td>\n",
       "      <td>[Others, Family/Animation, Horror, Drama, Fant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>0.779588</td>\n",
       "      <td>0.079820</td>\n",
       "      <td>0.020288</td>\n",
       "      <td>0.086737</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>0.018821</td>\n",
       "      <td>[Others, Family/Animation, Horror, Drama, Fant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168570</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Drama, Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168571</th>\n",
       "      <td>0.190531</td>\n",
       "      <td>0.587667</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>0.033155</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.009787</td>\n",
       "      <td>0.167410</td>\n",
       "      <td>[Thriller, Romance, Drama, Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168571</th>\n",
       "      <td>0.662094</td>\n",
       "      <td>0.230744</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.050244</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>0.031725</td>\n",
       "      <td>0.016653</td>\n",
       "      <td>[Thriller, Romance, Drama, Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168571</th>\n",
       "      <td>0.825387</td>\n",
       "      <td>0.029670</td>\n",
       "      <td>0.059088</td>\n",
       "      <td>0.023844</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>0.046947</td>\n",
       "      <td>[Thriller, Romance, Drama, Others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168571</th>\n",
       "      <td>0.039524</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.728655</td>\n",
       "      <td>0.039738</td>\n",
       "      <td>0.107170</td>\n",
       "      <td>0.080134</td>\n",
       "      <td>[Thriller, Romance, Drama, Others]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20311 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         neutral       joy  surprise   disgust      fear     anger   sadness  \\\n",
       "330     0.446200  0.147301  0.138631  0.118294  0.077507  0.038214  0.033855   \n",
       "3217    0.065840  0.003035  0.096655  0.005681  0.782216  0.042827  0.003746   \n",
       "3217    0.144797  0.003058  0.014325  0.214261  0.085287  0.397198  0.141074   \n",
       "3217    0.042516  0.018551  0.013053  0.073122  0.021625  0.737254  0.093879   \n",
       "3217    0.779588  0.079820  0.020288  0.086737  0.003069  0.011677  0.018821   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "168570       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "168571  0.190531  0.587667  0.010018  0.033155  0.001434  0.009787  0.167410   \n",
       "168571  0.662094  0.230744  0.004565  0.050244  0.003976  0.031725  0.016653   \n",
       "168571  0.825387  0.029670  0.059088  0.023844  0.006891  0.008173  0.046947   \n",
       "168571  0.039524  0.003780  0.001000  0.728655  0.039738  0.107170  0.080134   \n",
       "\n",
       "                                                 category  \n",
       "330                                       [Comedy, Drama]  \n",
       "3217    [Others, Family/Animation, Horror, Drama, Fant...  \n",
       "3217    [Others, Family/Animation, Horror, Drama, Fant...  \n",
       "3217    [Others, Family/Animation, Horror, Drama, Fant...  \n",
       "3217    [Others, Family/Animation, Horror, Drama, Fant...  \n",
       "...                                                   ...  \n",
       "168570                                    [Drama, Others]  \n",
       "168571                 [Thriller, Romance, Drama, Others]  \n",
       "168571                 [Thriller, Romance, Drama, Others]  \n",
       "168571                 [Thriller, Romance, Drama, Others]  \n",
       "168571                 [Thriller, Romance, Drama, Others]  \n",
       "\n",
       "[20311 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extended['summary_segmented'] = df_extended['summary'].iloc[:1000].apply(summary_to_segment)\n",
    "df_emotions_extended = create_df_emotions_with_every_film(df_extended)\n",
    "df_emotions_extended.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([   330,   3217,   3333,   3746,   3837,   3947,   4227,   4231,   4560,\n",
       "         4726,\n",
       "       ...\n",
       "       167857, 167924, 168483, 168491, 168498, 168551, 168554, 168561, 168570,\n",
       "       168571],\n",
       "      dtype='int64', length=1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_idx = df_emotions_extended.index.unique()\n",
    "unique_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ada)",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
