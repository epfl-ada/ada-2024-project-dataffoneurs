{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Findings from Our Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\march\\anaconda3\\envs\\ada\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\march\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.scripts import data_cleaning\n",
    "from src.scripts import data_modification\n",
    "from src.scripts import sentiment_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis dives into various aspects of cinema data, exploring questions such as the distribution of movie genres, gender representation over decades, and the emotions expressed in films. We focus mostly on movie related data for our project since it is our main focus point, however, we did also clean and browse character and actor data in case we decide that we want to include them for any reason. \n",
    "\n",
    "We have decided to only report images of our plots without the code to avoid cluttering this notebook but in case you would need it, you can find all related code and the plots in the src/scripts/notebook folder for a detailed step-by-step walkthrough. Concerning functional data pipelines like data cleaning, sentiment analysis and data modifications, we will call them from this notebook to give an idea of what the dataframes we work with look like. The scripts are located in src/scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whatâ€™s in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we tried to thoroughly clean the data in its entirety but especially plot summaries and movie related data. We removed tags, citations and most of weird characters from the movie summaries. We unified dates and in some cases removed the complete dates to keep only the year. We cleaned box office data by removing strings or changing them into numerical values and checked the bounds on some field (for example age should not be negative). We removed ids and columns we will mostly not use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Wikipedia_movie_ID', 'summary', 'Freebase_movie_ID', 'Movie_name',\n",
      "       'Movie_release_date', 'Movie_box_office_revenue', 'Movie_runtime',\n",
      "       'Movie_languages', 'Movie_countries', 'Movie_genres'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>summary</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42248</th>\n",
       "      <td>18581839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/04g04wt</td>\n",
       "      <td>The Great King</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.0</td>\n",
       "      <td>German Language</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Drama, Black-and-white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia_movie_ID summary Freebase_movie_ID      Movie_name  \\\n",
       "42248            18581839     NaN        /m/04g04wt  The Great King   \n",
       "\n",
       "       Movie_release_date  Movie_box_office_revenue  Movie_runtime  \\\n",
       "42248              1942.0                       NaN          118.0   \n",
       "\n",
       "       Movie_languages Movie_countries            Movie_genres  \n",
       "42248  German Language         Germany  Drama, Black-and-white  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data_movie = data_cleaning.movie_data_cleaning_pipeline()\n",
    "print(cleaned_data_movie.columns)\n",
    "cleaned_data_movie.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.184000e+04</td>\n",
       "      <td>39372.000000</td>\n",
       "      <td>8.401000e+03</td>\n",
       "      <td>6.129100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.741181e+07</td>\n",
       "      <td>1977.548816</td>\n",
       "      <td>4.799363e+07</td>\n",
       "      <td>1.118192e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.098881e+07</td>\n",
       "      <td>30.938137</td>\n",
       "      <td>1.121753e+08</td>\n",
       "      <td>4.360070e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.300000e+02</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.324745e+06</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>2.083193e+06</td>\n",
       "      <td>8.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.779234e+07</td>\n",
       "      <td>1989.000000</td>\n",
       "      <td>1.063969e+07</td>\n",
       "      <td>9.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.716129e+07</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>4.071696e+07</td>\n",
       "      <td>1.060000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.750192e+07</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2.782275e+09</td>\n",
       "      <td>1.079281e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia_movie_ID  Movie_release_date  Movie_box_office_revenue  \\\n",
       "count        8.184000e+04        39372.000000              8.401000e+03   \n",
       "mean         1.741181e+07         1977.548816              4.799363e+07   \n",
       "std          1.098881e+07           30.938137              1.121753e+08   \n",
       "min          3.300000e+02         1892.000000              1.000000e+04   \n",
       "25%          7.324745e+06         1952.000000              2.083193e+06   \n",
       "50%          1.779234e+07         1989.000000              1.063969e+07   \n",
       "75%          2.716129e+07         2005.000000              4.071696e+07   \n",
       "max          3.750192e+07         2016.000000              2.782275e+09   \n",
       "\n",
       "       Movie_runtime  \n",
       "count   6.129100e+04  \n",
       "mean    1.118192e+02  \n",
       "std     4.360070e+03  \n",
       "min     0.000000e+00  \n",
       "25%     8.100000e+01  \n",
       "50%     9.300000e+01  \n",
       "75%     1.060000e+02  \n",
       "max     1.079281e+06  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data_movie.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Wikipedia_movie_ID', 'Freebase_movie_ID', 'Movie_release_date',\n",
      "       'Character_name', 'Actor_date_of_birth', 'Actor_gender',\n",
      "       'Actor_height_(in meters)', 'Actor_ethnicity_(Freebase ID)',\n",
      "       'Actor_name', 'Actor_age_at_movie_release',\n",
      "       'Freebase_character/actor_map_ID', 'Freebase_character_ID',\n",
      "       'Freebase_actor_ID', 'unique_character_name', 'character_types',\n",
      "       'character', 'movie'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Character_name</th>\n",
       "      <th>Actor_date_of_birth</th>\n",
       "      <th>Actor_gender</th>\n",
       "      <th>Actor_height_(in meters)</th>\n",
       "      <th>Actor_ethnicity_(Freebase ID)</th>\n",
       "      <th>Actor_name</th>\n",
       "      <th>Actor_age_at_movie_release</th>\n",
       "      <th>Freebase_character/actor_map_ID</th>\n",
       "      <th>Freebase_character_ID</th>\n",
       "      <th>Freebase_actor_ID</th>\n",
       "      <th>unique_character_name</th>\n",
       "      <th>character_types</th>\n",
       "      <th>character</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290201</th>\n",
       "      <td>30233816.0</td>\n",
       "      <td>/m/0g56dc1</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sylvia Panacione</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0gkk82k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0gc1rqk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Wikipedia_movie_ID Freebase_movie_ID  Movie_release_date  \\\n",
       "290201          30233816.0        /m/0g56dc1              2010.0   \n",
       "\n",
       "       Character_name  Actor_date_of_birth Actor_gender  \\\n",
       "290201            NaN                  NaN            F   \n",
       "\n",
       "        Actor_height_(in meters) Actor_ethnicity_(Freebase ID)  \\\n",
       "290201                       NaN                           NaN   \n",
       "\n",
       "              Actor_name  Actor_age_at_movie_release  \\\n",
       "290201  Sylvia Panacione                         NaN   \n",
       "\n",
       "       Freebase_character/actor_map_ID Freebase_character_ID  \\\n",
       "290201                      /m/0gkk82k                   NaN   \n",
       "\n",
       "       Freebase_actor_ID unique_character_name character_types character movie  \n",
       "290201        /m/0gc1rqk                   NaN             NaN       NaN   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_character_data = data_cleaning.character_data_cleaning_pipeline()\n",
    "print(clean_character_data.columns)\n",
    "clean_character_data.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/scripts/plots/movie_exploration/Percentage_of_Missing_Data_for_Movie_Characteristics.png\" alt=\"box off per cat\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/scripts/plots/actor_exploration/Percentage_of_Missing_Data_for_Actor_Characteristics.png\" alt=\"box off per cat\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These visualizations highlight the percentage of missing data for both movie and actor characteristics. Some key insights from these two plots are that some categories, like movie summaries or box office revenue have significant gaps that could affect our following analysis. Since our main point of interests are summaries and box offices, we will use scraping to remediate the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/scripts/plots/movie_exploration/Distribution_of_the_summary_that_have_length_inf_to_5000_and_1000.png\" alt=\"box off per cat\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging deeper into the plot summaries data, we can observe that a certain amount of summary have less than 200 words. To thoroughly analyze emotion evolution throughout the summaries, we decided to decide on a cutoff value and scrape both missing plots from Wikipiedia when possible and summaries that are to short.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web-Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed in the various plots, approximately 40% of film summaries and over 90% of box office values are missing, both of which are critical for our analysis. To address these gaps in the original CMU dataset, we have decided to supplement it with additional information from the films' Wikipedia pages.\n",
    "\n",
    "Our focus is on films with missing or very short summaries (fewer than 200 words), for which we retrieve more detailed summaries from Wikipedia. This approach ensures that the sentiment analysis performed later has a sufficiently robust dataset to yield meaningful insights. Additionally, since predicting box office revenue is a key objective, we also scrape box office data from Wikipedia to enrich the dataset.\n",
    "\n",
    "The results presented here reflect the outcome of scraping applied to a sample of 2,000 films from the CMU dataset. This process enriches our data, specifically targeting films with incomplete summaries (replacing those under 200 words with the Wikipedia entry) and adding missing box office values. Regarding the data size, as we have applied our scraping techniques to a smaller sample of 2000 elements with a running time of 12 minutes for the summaries and 25 minutes for the box office revenues, we estimate a maximal running time of 8 hours and 16 hours. Nonetheless, we expect our running time to be lower as we will impose higher validity and usefulness constraints on our dataset's elements, disqualifying and dropping outlier elements (too short \"films\", films with too many unknows unable to be scraped,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\movie_exploration\\distribution_summary_length.png\" alt=\"Dist plots\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we present the distribution of summary lengths for the original CMU dataset (labeled \"Before\") alongside the enriched CMU dataset, supplemented with web-scraped data from Wikipedia (labeled \"After\").\n",
    "\n",
    "When comparing the two distributions of summary lengths, we observe that after scraping, there is an increase in the number of longer summaries, subsequently accompanied by a decrease in the number of shorter ones. This shift is further balanced by the fact that some previously missing summaries (NaN values) have now been populated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\movie_exploration\\percentage_missing_values_box_office.png\" alt=\"Dist plots\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we present the results showing the percentage of missing box office values in the original CMU dataset (\"Before scraping\") compared to the enriched dataset supplemented with web scraping (\"After scraping\").\n",
    "\n",
    "After scraping, we observe a reduction of more than 25% in the number of missing values for the box office revenue category in our sample of 2,000 entries. We can observe the successful outcomes of enriching our dataset through web scraping, and we rely on this enriched dataset to ensure it is robust enough to address our research questions.\n",
    "\n",
    "If needed the web-scraping related code can be found in src/scripts/notebook/data_scraping.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender parity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the proportion of male and female in the movie industry vary accross time and continent ? We clearly see that the industry is dominated by male characters consistently across all continents and decades. This does not relate directly to our analysis but we found it interesting to note."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/scripts/plots/actor_exploration/Gender_Proportion_Across_Decades_by_Continent.png\" alt=\"box off per cat\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres and Geographic Distribution \n",
    "\n",
    "Because of the astronomic number of genres in the data (about 360), we decided to handcraft a mapping to go down from 300 plus genres of movies to about a dozen. While our mapping may be a point of discussion among movie enthousiasts, we find it a good approximation to a more general genre classification. We also took the same route about geographical location, classifying countries by continent. The mapping themselves can be found in the notebook or scripts about data modifications. Our dataframe is therefore added with a continent and category column. This allows us to draw distribution per genre/continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>summary</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "      <th>category</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64853</th>\n",
       "      <td>28615549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0czblhj</td>\n",
       "      <td>The Phantom</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>English Language</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Thriller, Mystery, Horror</td>\n",
       "      <td>[Thriller, Horror]</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia_movie_ID summary Freebase_movie_ID   Movie_name  \\\n",
       "64853            28615549     NaN        /m/0czblhj  The Phantom   \n",
       "\n",
       "       Movie_release_date  Movie_box_office_revenue  Movie_runtime  \\\n",
       "64853              1931.0                       NaN           61.0   \n",
       "\n",
       "        Movie_languages           Movie_countries               Movie_genres  \\\n",
       "64853  English Language  United States of America  Thriller, Mystery, Horror   \n",
       "\n",
       "                 category      continent  \n",
       "64853  [Thriller, Horror]  North America  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_data = data_modification.all_data_transformations()\n",
    "modified_data.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/scripts/plots/movie_exploration/Distribution_of_Movies_by_Continent.png\" alt=\"box off per cat\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that North America is predominant in the field, followed by Europe and Asia. The other continents represent less than 5% of the film industry. This point leads us to believe that considering an analysis with and without North America could potentially bring out interesting differences as North America is overwhelmingly over-represented.\n",
    "\n",
    "Now let's take a look at the genres distribution in films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/scripts/plots/movie_exploration/Distribution_of_Movies_genres.png\" alt=\"box off per cat\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drama is the most common genre, accounting for the largest proportion at approximately 26%. This is followed by comedy and thriller, which hold significant but smaller shares. The distribution suggests a diverse set of genres without a single dominant category, reflecting the varied preferences in cinematic storytelling. It also gives us a hint to what genre we will consider for the final analysis, as smaller genres may not be represented enough to give us readable results.\n",
    "\n",
    "Let's explore how the distribution of movie genres differs across continents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/scripts/plots/movie_exploration/distribution_of_film_per_continent.png\" alt=\"box off per cat\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The charts show drama as a dominant genre globally, with variations in preferences across continents. Comedy is more prominent in North America and Oceania, while action/adventure stands out in Asia. The \"others\" category highlights regional diversity and niche genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box office and relationship to release date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next wanted to explore what variables other than emotional evolution could explain box office success, to know be aware of already existing trends due to other parameters. The bar chart shows a clear upward trend in average box office earnings by decade and an increase in movie production. Earnings rose gradually from the 1910s to the 1960s, with a sharper increase starting in the 1970s, likely driven by advancements in technology, global market expansion, and blockbuster productions. The slight dip in the 2010s might be due to the data ending around 2015, capturing only part of the decade. This trend reflects both economic factors like inflation and the evolving scale of the film industry. Inflantion is a factor that affects any kind of financial comparison in time, taking care of it in our final results is also one of our goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/scripts/plots/movie_exploration/Number_of_Movies_per_Decade.png\" alt=\"box off per cat\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/scripts/plots/movie_exploration/Mean_Box_Office_Earnings_by_Decade.png\" alt=\"box off per cat\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the box office revenue varies accross genres and continent ? (We won't be looking at Africa or South America because we don't have enough box office revenue data for these continent.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/scripts/plots/movie_exploration/Box_Office_Revenue_by_Movie_Category_by_Continent2.png\" alt=\"box off per cat\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean box office revenue clearly varies across continents. Interestingly, some film genres achieve high box office success despite being minimally represented in the overall distribution. For instance, the Family/Animation category performs exceptionally well in Europe, even though it accounts for only 2.5% of the film distribution across continents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of our datastory will rely on sentiment analysis to analyze possible emotions throughout a movie approximated via its summary. We considered three possible sentiment analysis:\n",
    "\n",
    "1) We first use a semantic similarity model to aggregate sentences of close meaning together and segment the plot summary. This means we would first pass every sentence in the model that projects them into a high-dimension embedding and then use cosine similarity with a threshold to group our sentences. Finally, we would pass each segment through a sentiment analysis model that gives back scores across 7 emotions: anger, disgust, fear, joy, neutral, sadness, or surprise.\n",
    "2) Passing sentence by sentence in the same sentiment analysis model that gives back scores across 7 emotions: anger, disgust, fear, joy, neutral, sadness, or surprise.\n",
    "3) Using a simpler sentiment analysis model that gives only a positive/negative score per sentence.\n",
    "\n",
    "We remarked that segmenting plot summaries with the semantic model and a threshold of 0.5 would only group about 13% of sentences, so we decided to go with the sentences option. We choose to use option 2 with emotion classification but have an idea of double checking our results with the positive/negative classifier to make sure positive and negative emotions match a positive/negative score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\march\\anaconda3\\envs\\ada\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038214</td>\n",
       "      <td>0.118294</td>\n",
       "      <td>0.077507</td>\n",
       "      <td>0.147301</td>\n",
       "      <td>0.446200</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.138631</td>\n",
       "      <td>0</td>\n",
       "      <td>In order to prepare the role of an important o...</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040454</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>0.818398</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.061496</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>0.066630</td>\n",
       "      <td>0</td>\n",
       "      <td>After being pulled through a time portal, Ash ...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.260286</td>\n",
       "      <td>0.336119</td>\n",
       "      <td>0.070448</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.178517</td>\n",
       "      <td>0.142633</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>1</td>\n",
       "      <td>He is enslaved along with the captured Henry, ...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127714</td>\n",
       "      <td>0.681643</td>\n",
       "      <td>0.060334</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.046439</td>\n",
       "      <td>0.074760</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>2</td>\n",
       "      <td>Ash is thrown in a pit where he fights off a D...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029963</td>\n",
       "      <td>0.013735</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.758849</td>\n",
       "      <td>0.150335</td>\n",
       "      <td>0.007201</td>\n",
       "      <td>0.038758</td>\n",
       "      <td>3</td>\n",
       "      <td>After demanding Henry and his men be set free ...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.011017</td>\n",
       "      <td>0.125419</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.069069</td>\n",
       "      <td>0.755839</td>\n",
       "      <td>0.017873</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>4</td>\n",
       "      <td>He also grows attracted to Sheila, the sister ...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017308</td>\n",
       "      <td>0.035617</td>\n",
       "      <td>0.010424</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.879692</td>\n",
       "      <td>0.045444</td>\n",
       "      <td>0.007719</td>\n",
       "      <td>5</td>\n",
       "      <td>According to the Wise Man, the only way Ash ca...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.009902</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>0.018521</td>\n",
       "      <td>0.038465</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.403152</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>6</td>\n",
       "      <td>After bidding goodbye to Sheila, Ash starts hi...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.970422</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.011798</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>7</td>\n",
       "      <td>As he enters a haunted forest, an unseen force...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.034630</td>\n",
       "      <td>0.013735</td>\n",
       "      <td>0.016873</td>\n",
       "      <td>0.774963</td>\n",
       "      <td>0.140356</td>\n",
       "      <td>0.012839</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>8</td>\n",
       "      <td>Fleeing, he ducks into a windmill where he cra...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.216373</td>\n",
       "      <td>0.334922</td>\n",
       "      <td>0.160281</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.062754</td>\n",
       "      <td>0.217976</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>9</td>\n",
       "      <td>The small reflections of Ash climb out from th...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.114703</td>\n",
       "      <td>0.729286</td>\n",
       "      <td>0.017313</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.120255</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>10</td>\n",
       "      <td>One of the reflections dives down Ash's throat...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.011396</td>\n",
       "      <td>0.104904</td>\n",
       "      <td>0.009680</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.569980</td>\n",
       "      <td>0.046398</td>\n",
       "      <td>0.253487</td>\n",
       "      <td>11</td>\n",
       "      <td>When he arrives at the Necronomicon's location...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.004289</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.944450</td>\n",
       "      <td>0.005646</td>\n",
       "      <td>0.024672</td>\n",
       "      <td>12</td>\n",
       "      <td>Ash eventually finds the real one and attempts...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.069713</td>\n",
       "      <td>0.172178</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.708128</td>\n",
       "      <td>0.028711</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>13</td>\n",
       "      <td>However, forgetting the last word, he tries to...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.044487</td>\n",
       "      <td>0.786035</td>\n",
       "      <td>0.076910</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.055434</td>\n",
       "      <td>0.028157</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>14</td>\n",
       "      <td>He then grabs the book from the cradle, and ru...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.025803</td>\n",
       "      <td>0.007354</td>\n",
       "      <td>0.935768</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.017421</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>15</td>\n",
       "      <td>During Ash's panicked ride back, his evil copy...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.115775</td>\n",
       "      <td>0.116528</td>\n",
       "      <td>0.012150</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>0.651397</td>\n",
       "      <td>0.093571</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>16</td>\n",
       "      <td>Despite causing the predicament faced by the M...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.139321</td>\n",
       "      <td>0.205160</td>\n",
       "      <td>0.126325</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.289325</td>\n",
       "      <td>0.175376</td>\n",
       "      <td>0.059049</td>\n",
       "      <td>17</td>\n",
       "      <td>However, Sheila is captured by a Flying Deadit...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.065463</td>\n",
       "      <td>0.060227</td>\n",
       "      <td>0.017016</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.828393</td>\n",
       "      <td>0.015006</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>18</td>\n",
       "      <td>Ash becomes determined to lead the humans agai...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.043871</td>\n",
       "      <td>0.068249</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.181740</td>\n",
       "      <td>0.692527</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.006316</td>\n",
       "      <td>19</td>\n",
       "      <td>Reluctantly, the people agree to join Ash.</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.022947</td>\n",
       "      <td>0.023309</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.388981</td>\n",
       "      <td>0.542997</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>20</td>\n",
       "      <td>Using scientific knowledge from textbooks in t...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.056030</td>\n",
       "      <td>0.629016</td>\n",
       "      <td>0.026499</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.216114</td>\n",
       "      <td>0.052588</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>21</td>\n",
       "      <td>After this, he is brought back to his own time...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.013817</td>\n",
       "      <td>0.025881</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.029925</td>\n",
       "      <td>0.782059</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.126954</td>\n",
       "      <td>22</td>\n",
       "      <td>Later, Ash is at the S-Mart store telling a ma...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.017756</td>\n",
       "      <td>0.816511</td>\n",
       "      <td>0.072793</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.073305</td>\n",
       "      <td>0.011063</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>23</td>\n",
       "      <td>A female customer becomes possessed by a demon...</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anger   disgust      fear       joy   neutral   sadness  surprise  \\\n",
       "0   0.038214  0.118294  0.077507  0.147301  0.446200  0.033855  0.138631   \n",
       "1   0.040454  0.007021  0.818398  0.002523  0.061496  0.003478  0.066630   \n",
       "2   0.260286  0.336119  0.070448  0.002892  0.178517  0.142633  0.009105   \n",
       "3   0.127714  0.681643  0.060334  0.001472  0.046439  0.074760  0.007639   \n",
       "4   0.029963  0.013735  0.001158  0.758849  0.150335  0.007201  0.038758   \n",
       "5   0.011017  0.125419  0.002716  0.069069  0.755839  0.017873  0.018066   \n",
       "6   0.017308  0.035617  0.010424  0.003796  0.879692  0.045444  0.007719   \n",
       "7   0.009902  0.018827  0.018521  0.038465  0.503885  0.403152  0.007247   \n",
       "8   0.001351  0.004731  0.970422  0.000833  0.011798  0.004374  0.006491   \n",
       "9   0.034630  0.013735  0.016873  0.774963  0.140356  0.012839  0.006604   \n",
       "10  0.216373  0.334922  0.160281  0.003257  0.062754  0.217976  0.004438   \n",
       "11  0.114703  0.729286  0.017313  0.002055  0.120255  0.008734  0.007654   \n",
       "12  0.011396  0.104904  0.009680  0.004154  0.569980  0.046398  0.253487   \n",
       "13  0.006522  0.004289  0.002517  0.011905  0.944450  0.005646  0.024672   \n",
       "14  0.069713  0.172178  0.006832  0.004222  0.708128  0.028711  0.010215   \n",
       "15  0.044487  0.786035  0.076910  0.001455  0.055434  0.028157  0.007521   \n",
       "16  0.025803  0.007354  0.935768  0.001632  0.017421  0.008358  0.003663   \n",
       "17  0.115775  0.116528  0.012150  0.009159  0.651397  0.093571  0.001421   \n",
       "18  0.139321  0.205160  0.126325  0.005445  0.289325  0.175376  0.059049   \n",
       "19  0.065463  0.060227  0.017016  0.009488  0.828393  0.015006  0.004406   \n",
       "20  0.043871  0.068249  0.002084  0.181740  0.692527  0.005213  0.006316   \n",
       "21  0.022947  0.023309  0.004043  0.388981  0.542997  0.005155  0.012569   \n",
       "22  0.056030  0.629016  0.026499  0.001776  0.216114  0.052588  0.017977   \n",
       "23  0.013817  0.025881  0.009880  0.029925  0.782059  0.011484  0.126954   \n",
       "24  0.017756  0.816511  0.072793  0.001832  0.073305  0.011063  0.006739   \n",
       "\n",
       "    sentence_id                                           sentence  \\\n",
       "0             0  In order to prepare the role of an important o...   \n",
       "1             0  After being pulled through a time portal, Ash ...   \n",
       "2             1  He is enslaved along with the captured Henry, ...   \n",
       "3             2  Ash is thrown in a pit where he fights off a D...   \n",
       "4             3  After demanding Henry and his men be set free ...   \n",
       "5             4  He also grows attracted to Sheila, the sister ...   \n",
       "6             5  According to the Wise Man, the only way Ash ca...   \n",
       "7             6  After bidding goodbye to Sheila, Ash starts hi...   \n",
       "8             7  As he enters a haunted forest, an unseen force...   \n",
       "9             8  Fleeing, he ducks into a windmill where he cra...   \n",
       "10            9  The small reflections of Ash climb out from th...   \n",
       "11           10  One of the reflections dives down Ash's throat...   \n",
       "12           11  When he arrives at the Necronomicon's location...   \n",
       "13           12  Ash eventually finds the real one and attempts...   \n",
       "14           13  However, forgetting the last word, he tries to...   \n",
       "15           14  He then grabs the book from the cradle, and ru...   \n",
       "16           15  During Ash's panicked ride back, his evil copy...   \n",
       "17           16  Despite causing the predicament faced by the M...   \n",
       "18           17  However, Sheila is captured by a Flying Deadit...   \n",
       "19           18  Ash becomes determined to lead the humans agai...   \n",
       "20           19         Reluctantly, the people agree to join Ash.   \n",
       "21           20  Using scientific knowledge from textbooks in t...   \n",
       "22           21  After this, he is brought back to his own time...   \n",
       "23           22  Later, Ash is at the S-Mart store telling a ma...   \n",
       "24           23  A female customer becomes possessed by a demon...   \n",
       "\n",
       "    Wikipedia_movie_ID  \n",
       "0                  330  \n",
       "1                 3217  \n",
       "2                 3217  \n",
       "3                 3217  \n",
       "4                 3217  \n",
       "5                 3217  \n",
       "6                 3217  \n",
       "7                 3217  \n",
       "8                 3217  \n",
       "9                 3217  \n",
       "10                3217  \n",
       "11                3217  \n",
       "12                3217  \n",
       "13                3217  \n",
       "14                3217  \n",
       "15                3217  \n",
       "16                3217  \n",
       "17                3217  \n",
       "18                3217  \n",
       "19                3217  \n",
       "20                3217  \n",
       "21                3217  \n",
       "22                3217  \n",
       "23                3217  \n",
       "24                3217  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As an example, we run it on 2 plot\n",
    "sentiment_df = sentiment_analysis.sentiment_analysis_sentences(limit=2)\n",
    "sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, we now have an emotion score for each sentence. The next is to make it comparable across movies. We remarked that the average plot length for now (before scraping) is about 20 sentences and chose 20 as the number of timesteps across a movie where we will consider the emotions. This number may change as the length of our overall plots augments. In the data, we now use simple interpolation and fill missing values with extrapolation to obtain the emotional evolution of movies across 20 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\march\\anaconda3\\envs\\ada\\Lib\\site-packages\\scipy\\interpolate\\_interpolate.py:712: RuntimeWarning: invalid value encountered in divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>timestep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.040454</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>0.818398</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.061496</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>0.066630</td>\n",
       "      <td>3217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.232376</td>\n",
       "      <td>0.408861</td>\n",
       "      <td>0.068319</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.150711</td>\n",
       "      <td>0.128344</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>3217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.086556</td>\n",
       "      <td>0.400418</td>\n",
       "      <td>0.035418</td>\n",
       "      <td>0.320368</td>\n",
       "      <td>0.090185</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.020742</td>\n",
       "      <td>3217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.323199</td>\n",
       "      <td>0.532759</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>0.025689</td>\n",
       "      <td>3217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.016314</td>\n",
       "      <td>0.049796</td>\n",
       "      <td>0.009207</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>0.860136</td>\n",
       "      <td>0.041091</td>\n",
       "      <td>0.009353</td>\n",
       "      <td>3217</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.068621</td>\n",
       "      <td>0.036484</td>\n",
       "      <td>0.477986</td>\n",
       "      <td>0.382164</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>3217</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.010108</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.719488</td>\n",
       "      <td>0.204552</td>\n",
       "      <td>0.045629</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>3217</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.120718</td>\n",
       "      <td>0.165876</td>\n",
       "      <td>0.084803</td>\n",
       "      <td>0.409418</td>\n",
       "      <td>0.103597</td>\n",
       "      <td>0.110009</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>3217</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.146809</td>\n",
       "      <td>0.604750</td>\n",
       "      <td>0.062461</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.102097</td>\n",
       "      <td>0.074810</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>3217</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.022271</td>\n",
       "      <td>0.170628</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.522641</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>0.227610</td>\n",
       "      <td>3217</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.013173</td>\n",
       "      <td>0.021961</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.011096</td>\n",
       "      <td>0.919574</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>0.023150</td>\n",
       "      <td>3217</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.061747</td>\n",
       "      <td>0.366028</td>\n",
       "      <td>0.028962</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.502014</td>\n",
       "      <td>0.028536</td>\n",
       "      <td>0.009364</td>\n",
       "      <td>3217</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.034653</td>\n",
       "      <td>0.376203</td>\n",
       "      <td>0.528941</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.035427</td>\n",
       "      <td>0.017737</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>3217</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.092098</td>\n",
       "      <td>0.087798</td>\n",
       "      <td>0.255207</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.484561</td>\n",
       "      <td>0.071147</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>3217</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.138081</td>\n",
       "      <td>0.200495</td>\n",
       "      <td>0.120315</td>\n",
       "      <td>0.005640</td>\n",
       "      <td>0.308382</td>\n",
       "      <td>0.171071</td>\n",
       "      <td>0.056016</td>\n",
       "      <td>3217</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.062053</td>\n",
       "      <td>0.061494</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.036686</td>\n",
       "      <td>0.806941</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>3217</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.036162</td>\n",
       "      <td>0.051692</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.258092</td>\n",
       "      <td>0.637437</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>3217</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.373981</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.164810</td>\n",
       "      <td>0.353749</td>\n",
       "      <td>0.032616</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>3217</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.022704</td>\n",
       "      <td>0.152857</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.023999</td>\n",
       "      <td>0.662913</td>\n",
       "      <td>0.020137</td>\n",
       "      <td>0.104011</td>\n",
       "      <td>3217</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.017756</td>\n",
       "      <td>0.816511</td>\n",
       "      <td>0.072793</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.073305</td>\n",
       "      <td>0.011063</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>3217</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anger   disgust      fear       joy   neutral   sadness  surprise  \\\n",
       "20  0.040454  0.007021  0.818398  0.002523  0.061496  0.003478  0.066630   \n",
       "21  0.232376  0.408861  0.068319  0.002593  0.150711  0.128344  0.008796   \n",
       "22  0.086556  0.400418  0.035418  0.320368  0.090185  0.046314  0.020742   \n",
       "23  0.017997  0.084273  0.002142  0.323199  0.532759  0.013941  0.025689   \n",
       "24  0.016314  0.049796  0.009207  0.014102  0.860136  0.041091  0.009353   \n",
       "25  0.009452  0.018085  0.068621  0.036484  0.477986  0.382164  0.007207   \n",
       "26  0.010108  0.007101  0.719488  0.204552  0.045629  0.006602  0.006521   \n",
       "27  0.120718  0.165876  0.084803  0.409418  0.103597  0.110009  0.005578   \n",
       "28  0.146809  0.604750  0.062461  0.002435  0.102097  0.074810  0.006639   \n",
       "29  0.022271  0.170628  0.010483  0.003933  0.522641  0.042434  0.227610   \n",
       "30  0.013173  0.021961  0.002972  0.011096  0.919574  0.008074  0.023150   \n",
       "31  0.061747  0.366028  0.028962  0.003348  0.502014  0.028536  0.009364   \n",
       "32  0.034653  0.376203  0.528941  0.001548  0.035427  0.017737  0.005491   \n",
       "33  0.092098  0.087798  0.255207  0.007178  0.484561  0.071147  0.002011   \n",
       "34  0.138081  0.200495  0.120315  0.005640  0.308382  0.171071  0.056016   \n",
       "35  0.062053  0.061494  0.014659  0.036686  0.806941  0.013460  0.004708   \n",
       "36  0.036162  0.051692  0.002806  0.258092  0.637437  0.005192  0.008620   \n",
       "37  0.042100  0.373981  0.017044  0.164810  0.353749  0.032616  0.015700   \n",
       "38  0.022704  0.152857  0.013379  0.023999  0.662913  0.020137  0.104011   \n",
       "39  0.017756  0.816511  0.072793  0.001832  0.073305  0.011063  0.006739   \n",
       "\n",
       "    Wikipedia_movie_ID  timestep  \n",
       "20                3217         0  \n",
       "21                3217         1  \n",
       "22                3217         2  \n",
       "23                3217         3  \n",
       "24                3217         4  \n",
       "25                3217         5  \n",
       "26                3217         6  \n",
       "27                3217         7  \n",
       "28                3217         8  \n",
       "29                3217         9  \n",
       "30                3217        10  \n",
       "31                3217        11  \n",
       "32                3217        12  \n",
       "33                3217        13  \n",
       "34                3217        14  \n",
       "35                3217        15  \n",
       "36                3217        16  \n",
       "37                3217        17  \n",
       "38                3217        18  \n",
       "39                3217        19  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_data = sentiment_analyis.interpolate_df(sentiment_df)\n",
    "interpolated_data.dropna(inplace=True)\n",
    "interpolated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this, it is easy to groupby anything we would want (continent, category, revenue etc etc) and we will show our preliminary results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical notes on runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have evaluated our pipeline over 5000 thousand films only for now in order to make sure that it runs smoothly and to see if we obtained results that are interesting. Running 5000 movies on a google colab notebook with an A100 GPU takes about 10-13 minutes, so we estimate that after data scraping and we will most likely evaluate about 80% of the dataset, which is about 60'000 movies for an estimated runtime of 2-3 hours.\n",
    "\n",
    "The following results are therefore only a 5000 movies subset but we expect trends to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of emotions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do emotions progress over the course of a movie? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Average_Evolution_of_Emotions_Across_Timesteps_for_All_Movies.png\" alt=\"box off per cat\" width=\"1400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first graph shows the averaged evolution of emotions over the course of a movie, with neutral emotions being the most prominent and steadily increasing toward the end. Disgust, on the other hand, maintains a consistent presence throughout the movie. The second graph, which normalizes the emotions, reveals more dynamic changes, with surprise and fear peaking early on and then declining, while neutral emotions gradually dominate as the movie progresses. These trends reflect typical emotional pacing in storytelling, balancing tension and resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a closer look at each emotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Anger_across_Timesteps_for_Each_Genre.png\" alt=\"box off per cat\" width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Disgust_across_Timesteps_for_Each_Genre.png\" alt=\"box off per cat\" width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Fear_across_Timesteps_for_Each_Genre.png\" alt=\"box off per cat\" width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Sadness_across_Timesteps_for_Each_Genre.png\" alt=\"box off per cat\" width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Joy_across_Timesteps_for_Each_Genre.png\" alt=\"box off per cat\" width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Surprise_across_Timesteps_for_Each_Genre.png\" alt=\"box off per cat\" width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Neutral_across_Timesteps_for_Each_Genre.png\" alt=\"box off per cat\" width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter the genre, the evolution of emotions follows a similar pattern. Negative emotions like anger, fear, and disgust tend to rise during the first half of a movie, building tension, while emotions like neutrality and joy increase towards the end, reflecting narrative resolution. This consistency suggests that filmmakers across genres rely on a common emotional arc to engage audiences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of emotions across continents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it differ across continents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Emotions_across_Timesteps_in_North_America.png\" alt=\"box off per cat\" width=\"1600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Emotions_across_Timesteps_in_Europe.png\" alt=\"box off per cat\" width=\"1600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Emotions_across_Timesteps_in_Asia.png\" alt=\"box off per cat\" width=\"1600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Emotions_across_Timesteps_in_Oceania.png\" alt=\"box off per cat\" width=\"1600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across North America, Europe, Asia, and Oceania, movies follow a consistent emotional pattern: negative emotions like anger, disgust, and fear rise early to build tension, while joy and neutrality increase toward the end, signaling resolution. Sadness dips mid-story but often peaks near the conclusion, aligning with emotional climaxes. \n",
    "\n",
    "We can also observe that North America follows a fixed emotional pattern, with steady rises and falls in emotions. It may be due to the bigger amount of films in that region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Emotions_across_Timesteps_in_South_America.png\" alt=\"box off per cat\" width=\"1600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\Normalized_Evolution_of_Emotions_across_Timesteps_in_Africa.png\" alt=\"box off per cat\" width=\"1600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note that the results for South America and Africa might be different from the four other continents because we lacks data for these two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we predict a movie's box office performance based on the data we have? We used a simple model, a Random Forest Regressor with the release date, the runtime, the  the categories, the continent and the mean emotion of the films. With this, we got a R-squared score of 0.124189, which is not really good. This mean we cannot predict the boxoffice with simple model.This is understandable, as we can see from the plots on the normalized evolutions of emotions accross timestep for each genre doesn't change much from one genre to another, which means that many features are of little use in predicting box office."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src\\scripts\\plots\\sentiment_analysis\\box_office_prediction2.png\" alt=\"box off per cat\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Our analysis provides an in-depth exploration of cinema-related data, focusing on various dimensions such as genre distribution, gender representation, box office trends, and the evolution of emotions in movies. The insights gained highlight several key aspects of the film industry while revealing areas where data limitations affect our conclusions.\n",
    "\n",
    "#### Key Findings:\n",
    "1. **Data Cleaning and Enrichment**:\n",
    "   - A significant portion of the original dataset, including movie summaries and box office data, contained missing or incomplete values.\n",
    "   - Through web scraping, we successfully enriched the dataset, reducing missing values by over 25% for box office data and improving the average quality of movie summaries.\n",
    "\n",
    "2. **Emotional Evolution in Movies**:\n",
    "   - Emotions in movies follow a consistent narrative arc across genres and continents:\n",
    "     - Negative emotions such as anger, fear, and disgust rise during the initial stages, building tension.\n",
    "     - Joy and neutrality increase toward the conclusion, reflecting narrative resolution.\n",
    "   - The trends suggest that filmmakers across the globe rely on a shared emotional structure to engage audiences.\n",
    "\n",
    "3. **Genre and Geographic Trends**:\n",
    "   - Drama dominates globally, accounting for 26% of films, followed by comedy and thriller.\n",
    "   - North America leads in film production, contributing the majority of the dataset, with Europe and Asia trailing behind. Other continents, such as South America and Africa, are underrepresented, limiting our ability to generalize findings for these regions.\n",
    "\n",
    "4. **Box Office Performance**:\n",
    "   - Our attempt to predict box office performance using a Random Forest Regressor yielded a low R-squared score of 0.124, indicating that the selected features (release date, runtime, categories, continent, and mean emotions) are insufficient for accurate prediction.\n",
    "   - The limited predictive power suggests that other factors, such as marketing budgets, star power, and audience reception, likely play a significant role in box office success.\n",
    "\n",
    "#### Limitations:\n",
    "- **Data Imbalance**: The overrepresentation of North American films skews global trends, making it difficult to draw conclusions for underrepresented regions.\n",
    "- **Feature Limitations**: Emotional arcs and basic film metadata, while insightful, are not strong predictors of box office performance without additional contextual factors.\n",
    "- **Incomplete Data**: Despite web scraping, some gaps remain, particularly for smaller film industries in South America and Africa.\n",
    "\n",
    "#### Next Steps:\n",
    "1. **Expand the Dataset**: Further scraping and validation for missing data, particularly in underrepresented regions, could improve the robustness of the analysis.\n",
    "2. **Explore Advanced Models**: Incorporating advanced machine learning models or external features (e.g., social media engagement, audience ratings) could enhance box office prediction.\n",
    "3. **Analyze Niche Genres**: Focused studies on niche genres or regional film trends could uncover unique patterns not evident in the broader analysis.\n",
    "\n",
    "In conclusion, this work lays a foundation for understanding emotional storytelling and genre trends in global cinema, while identifying areas for future research and data enrichment. The results emphasize the universal appeal of emotional arcs in movies and the challenges of predicting commercial success in such a complex and multi-faceted industry.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
